{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: gensim in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: six>=1.5.0 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from gensim) (1.15.0)\nRequirement already satisfied: scipy>=0.18.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from gensim) (1.4.1)\nRequirement already satisfied: numpy>=1.11.3 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from gensim) (1.17.5)\nRequirement already satisfied: smart-open>=1.8.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from gensim) (2.0.0)\nRequirement already satisfied: boto in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.3)\nRequirement already satisfied: requests in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\nRequirement already satisfied: botocore<1.18.0,>=1.17.3 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.3)\nRequirement already satisfied: idna<3,>=2.5 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.2)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.3->boto3->smart-open>=1.8.1->gensim) (2.8.1)\nRequirement already satisfied: docutils<0.16,>=0.10 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.3->boto3->smart-open>=1.8.1->gensim) (0.15.2)\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#NLP Environment setup \n",
    "from collections import Counter \n",
    "\n",
    "#Plotting \n",
    "import squarify\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "#NLP Libraries \n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer#NLP Environment setup \n",
    "from collections import Counter \n",
    "\n",
    "#Plotting \n",
    "import squarify\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "#NLP Libraries \n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_numeric, stem_text\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_non_alphanum, remove_stopwords, strip_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/noahpovis/Desktop/Buildweek22/Build Week 2 /DX.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(16278, 18)"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5426, 18)"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5427, 18)"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(i):\n",
    "    i = i.copy()\n",
    "    i.drop_duplicates(subset=['Organization Name','Funding Type'], inplace = True)\n",
    "    i.drop_duplicates(keep='first', inplace= True)\n",
    "    i['Raised Series A'] = np.where(i['Organization Name'].duplicated(), 1, 0)\n",
    "    i.drop_duplicates(subset='Organization Name', keep='last', inplace= True)\n",
    "    i['Money Raised Currency (in USD)'] = pd.to_numeric(i['Money Raised Currency (in USD)'], errors='coerce')\n",
    "    i['Total Funding Amount Currency (in USD)'] = pd.to_numeric(i['Total Funding Amount Currency (in USD)'], errors='coerce')\n",
    "    i['Announced Date'] = pd.to_datetime(i['Announced Date'], errors='coerce')\n",
    "    i['Total Funding Amount Currency (in USD)'] = pd.to_numeric(i['Total Funding Amount Currency (in USD)'], errors='coerce')\n",
    "    i  = i[i['Funding Type'] != 'Series A'] \n",
    "    return i \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean(train)\n",
    "val = clean(val)\n",
    "test = clean(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    12342\n1      180\nName: Raised Series A, dtype: int64"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "train['Raised Series A'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((12522, 19), (4546, 19), (4547, 19))"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "train.shape , val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3660"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "train['Investor Names'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns(text):\n",
    "    text = text.copy()\n",
    "    # new data frame with split value columns \n",
    "    new = text[\"Organization Industries\"].str.split(\",\", n = 7, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    text[\"Primary Industry\"]= new[0] \n",
    "    # making separate last name column from new data frame \n",
    "    text[\"Sub_Ind\"]= new[1] \n",
    "    text[\"Sub_Ind2\"]= new[2]\n",
    "    text[\"Sub_Ind3\"]= new[3]\n",
    "    text[\"Sub_Ind4\"]= new[4]\n",
    "    text[\"Sub_Ind5\"]= new[5]\n",
    "    text[\"Sub_Ind6\"]= new[6]\n",
    "    text[\"Sub_Ind7\"]= new[7]\n",
    "    # Dropping old Name columns \n",
    "    text.drop(columns =[\"Organization Industries\"], inplace = True)\n",
    "\n",
    "    #same thing but for investor column \n",
    "    new1 = text[\"Investor Names\"].str.split(\",\", n = 11, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    text[\"Investor1\"]= new1[0] \n",
    "    # making separate last name column from new data frame \n",
    "    text[\"Investor1\"]= new1[1] \n",
    "    text[\"Investor2\"]= new1[2]\n",
    "    text[\"Investor3\"]= new1[3]\n",
    "    text[\"Investor4\"]= new1[4]\n",
    "    text[\"Investor5\"]= new1[5]\n",
    "    text[\"Investor6\"]= new1[6]\n",
    "    text[\"Investor7\"]= new1[7]\n",
    "    text[\"Investor8\"]= new1[8]\n",
    "    text[\"Investor9\"]= new1[9]\n",
    "    text[\"Investor10\"]= new1[10]\n",
    "    text[\"Investor11\"]= new1[11]\n",
    "    # Dropping old Name columns \n",
    "    text.drop(columns =[\"Investor Names\"], inplace = True)\n",
    "    text.drop(columns =[\"Lead Investors\"], inplace = True)\n",
    "    text.drop(columns =[\"Number of Investors\"], inplace = True)\n",
    "    text = text[text['Money Raised'].notna()]\n",
    "    text = text[text['Organization Location'].notna()]\n",
    "    text = text[text['Primary Industry'].notna()]\n",
    "    text = text[text['Money Raised Currency (in USD)'].notna()]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return text \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split_columns(train)\n",
    "val = split_columns(val)\n",
    "test = split_columns(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Transaction Name', 'Transaction Name URL', 'Organization Name',\n       'Organization Name URL', 'Funding Type', 'Money Raised',\n       'Money Raised Currency', 'Money Raised Currency (in USD)',\n       'Announced Date', 'Total Funding Amount',\n       'Total Funding Amount Currency',\n       'Total Funding Amount Currency (in USD)', 'Organization Description',\n       'Organization Location', 'Raised Series A', 'Primary Industry',\n       'Sub_Ind', 'Sub_Ind2', 'Sub_Ind3', 'Sub_Ind4', 'Sub_Ind5', 'Sub_Ind6',\n       'Sub_Ind7', 'Investor1', 'Investor2', 'Investor3', 'Investor4',\n       'Investor5', 'Investor6', 'Investor7', 'Investor8', 'Investor9',\n       'Investor10', 'Investor11'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Transaction Name                             0\nTransaction Name URL                         0\nOrganization Name                            0\nOrganization Name URL                        0\nFunding Type                                 0\nMoney Raised                                 0\nMoney Raised Currency                        0\nMoney Raised Currency (in USD)               0\nAnnounced Date                               0\nTotal Funding Amount                         0\nTotal Funding Amount Currency                0\nTotal Funding Amount Currency (in USD)       0\nOrganization Description                     0\nOrganization Location                        0\nRaised Series A                              0\nPrimary Industry                             0\nSub_Ind                                   1068\nSub_Ind2                                  2556\nSub_Ind3                                  4677\nSub_Ind4                                  6013\nSub_Ind5                                  6840\nSub_Ind6                                  7356\nSub_Ind7                                  7604\nInvestor1                                 5301\nInvestor2                                 6231\nInvestor3                                 6826\nInvestor4                                 7211\nInvestor5                                 7448\nInvestor6                                 7609\nInvestor7                                 7741\nInvestor8                                 7805\nInvestor9                                 7850\nInvestor10                                7873\nInvestor11                                7893\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    7806\n1     127\nName: Raised Series A, dtype: int64"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "train['Raised Series A'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "750000.0"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "train['Money Raised Currency (in USD)'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'preprocessing_filter' function\n",
    "def preprocessing_filter(text):\n",
    "    '''\n",
    "    Cleans text for font size, whitespace,\n",
    "    removing stop words, and stripping non-alpha \n",
    "    numeric characters\n",
    "    '''\n",
    "    # Custom Preprocessing Filter\n",
    "    custom_filters = [lambda x: x.lower(),          # Lowercase\n",
    "                      strip_multiple_whitespaces,   # Remove numbers\n",
    "                      remove_stopwords,             # Remove stopwords\n",
    "                      strip_non_alphanum,           # Remove non-alpha numeric characters\n",
    "                     ]\n",
    "    \n",
    "    \n",
    "    # TEST / CHECK: Preprocess with 'custom_filters'\n",
    "    processed_text = preprocess_string(text, custom_filters)\n",
    "    \n",
    "    # Returning 'processed_text'\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_apply(k):\n",
    "    k[\"tokenized_Description\"] = k[\"Organization Description\"].apply(preprocessing_filter)\n",
    "    k.drop(columns =[\"Organization Description\"], inplace = True)\n",
    "    print(k.shape)\n",
    "\n",
    "    return k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(7933, 34)\n(2933, 34)\n(2914, 34)\n"
    }
   ],
   "source": [
    "train = function_apply(train)\n",
    "val = function_apply(val)\n",
    "test = function_apply(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'Raised Series A'\n",
    "X_train = train.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_val = val[target]\n",
    "X_test = test.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((7933, 31), (7933,))"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    2915\n1      18\nName: Raised Series A, dtype: int64"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "val['Raised Series A'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='median'),\n",
    "    XGBClassifier(n_estimators=100,\n",
    "                  random_state=42,\n",
    "                  n_jobs=-1          \n",
    ")\n",
    ")\n",
    "\n",
    "###scores = cross_val_score(pipeline, X_train, y_train, cv=10, \n",
    "                         ##scoring = 'average_precision')\n",
    "\n",
    "###scores_val = cross_val_score(pipeline, X_val, y_val, cv=10, \n",
    "                         ##scoring = 'average_precision')'''\n",
    "\n",
    "\n",
    "pipe = pipeline.fit(X_train, y_train);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "XGBoost Classifier val Recall Accuracy: 0.0\nXGBoost Classifier val Accuracy Score: 0.9911353562904875\nXGBoost Classifier val Precision Accuracy: 0.0\n"
    }
   ],
   "source": [
    "xgb_val = pipe.predict(X_val)\n",
    "print(\"XGBoost Classifier val Recall Accuracy:\", recall_score(y_val, xgb_val))\n",
    "print(\"XGBoost Classifier val Accuracy Score:\", accuracy_score(y_val, xgb_val))\n",
    "print(\"XGBoost Classifier val Precision Accuracy:\", precision_score(y_val, xgb_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[   0    1]\n [2925    8]]\n"
    }
   ],
   "source": [
    "# when i ran predict(on X_val, it predicted that 10 of the 18 'Yes' values incorrectly. This could explain why the precision and recall accuracy is so low. \n",
    "unique_elements, counts_elements = np.unique(xgb_val, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make another \n",
    "target = 'Raised Series A'\n",
    "X_train = train.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_val = val[target]\n",
    "X_test = test.drop(columns=[target,'tokenized_Description','Announced Date'])\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting imbalanced-learn\n  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n\u001b[K     |████████████████████████████████| 167 kB 839 kB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from imbalanced-learn) (0.15.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from imbalanced-learn) (1.17.5)\nRequirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from imbalanced-learn) (0.23.1)\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/noahpovis/opt/anaconda3/envs/unit2/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\nInstalling collected packages: imbalanced-learn\nSuccessfully installed imbalanced-learn-0.7.0\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "#install imbalance package\n",
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Seed Round - Fashion Kanvas'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-3989c2d97a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unit2/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Seed Round - Fashion Kanvas'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def corpora(d):\n",
    "    #'Dictionary' Representation of all the words in our corpus\n",
    "    #id2word = corpora.Dictionary(d[\"tokenized_Description\"])\n",
    "    #Removing extreme values from the dataset\n",
    "    #id2word.filter_extremes(no_below=5, no_above=0.95)\n",
    "    #bag of words(bow) representation of our corpus\n",
    "    #corpus = [id2word.doc2bow(text) for text in d[\"tokenized_Description\"]]\n",
    "    #return d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = corpora(train)\n",
    "#val = corpora(val)\n",
    "#test = corpora(test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Recall 0.20800000000000002 [0.   0.   0.   0.12 0.92]\nPrecision 0.008545885467614697 [0.         0.         0.         0.01038062 0.0323488 ]\nF1 0.016321656050955417 [0.         0.         0.         0.01910828 0.0625    ]\n"
    }
   ],
   "source": [
    "# precision, recall and F1\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall)\n",
    "precision = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision)\n",
    "f1 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "print('F1', np.mean(f1), f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitunit2condaf2d4faf30a5848cbbdf1cd45adcc297a",
   "display_name": "Python 3.7.7 64-bit ('unit2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}